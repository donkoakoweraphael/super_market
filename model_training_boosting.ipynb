{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "a861d1e6",
            "metadata": {},
            "source": [
                "# Model Training: Boosting Models (XGBoost & LightGBM)\n",
                "\n",
                "Ce notebook charge les donn√©es depuis `Data/` et entra√Æne des mod√®les de gradient boosting pour pr√©dire `target_7` et `target_30`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5f8cc3e",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import xgboost as xgb\n",
                "import lightgbm as lgb\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
                "import joblib\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "os.makedirs('trained_models', exist_ok=True)\n",
                "print(\"‚úÖ Biblioth√®ques import√©es.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b3520fc8",
            "metadata": {},
            "source": [
                "## Chargement des Donn√©es"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "86cf02a9",
            "metadata": {},
            "outputs": [],
            "source": [
                "train_path = 'Data/train_boosting.csv'\n",
                "test_path = 'Data/test_boosting.csv'\n",
                "\n",
                "if not os.path.exists(train_path) or not os.path.exists(test_path):\n",
                "    raise FileNotFoundError(\"Fichiers introuvables dans Data/.\")\n",
                "\n",
                "train_df = pd.read_csv(train_path)\n",
                "test_df = pd.read_csv(test_path)\n",
                "\n",
                "print(f\"üì¶ Train: {train_df.shape}, Test: {test_df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6219d22a",
            "metadata": {},
            "source": [
                "## Fonction d'Entra√Ænement\n",
                "Nous d√©finissons une fonction pour entra√Æner et √©valuer les mod√®les pour une cible donn√©e."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "73e9ffae",
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_evaluate_save(target_col, suffix):\n",
                "    print(f\"\\nüéØ Traitement pour {target_col}...\")\n",
                "    \n",
                "    # Pr√©paration des donn√©es\n",
                "    # On retire les deux targets des features\n",
                "    drop_cols = ['target_7', 'target_30']\n",
                "    \n",
                "    X_train = train_df.drop(columns=drop_cols, errors='ignore')\n",
                "    y_train = train_df[target_col]\n",
                "    \n",
                "    X_test = test_df.drop(columns=drop_cols, errors='ignore')\n",
                "    y_test = test_df[target_col]\n",
                "    \n",
                "    # Filtrage num√©rique uniquement\n",
                "    X_train = X_train.select_dtypes(include=[np.number])\n",
                "    X_test = X_test.select_dtypes(include=[np.number])\n",
                "    \n",
                "    # Alignement\n",
                "    X_train = X_train[X_test.columns]\n",
                "    \n",
                "    # --- XGBoost ---\n",
                "    print(\"  ‚è≥ XGBoost...\")\n",
                "    xgb_model = xgb.XGBRegressor(\n",
                "        n_estimators=1000,\n",
                "        learning_rate=0.05,\n",
                "        max_depth=6,\n",
                "        subsample=0.8,\n",
                "        colsample_bytree=0.8,\n",
                "        early_stopping_rounds=50,\n",
                "        random_state=42,\n",
                "        n_jobs=-1\n",
                "    )\n",
                "    xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
                "    \n",
                "    # √âvaluation XGB\n",
                "    xgb_pred = xgb_model.predict(X_test)\n",
                "    xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
                "    print(f\"    ‚úÖ XGB RMSE: {xgb_rmse:.4f}\")\n",
                "    \n",
                "    # Sauvegarde XGB\n",
                "    joblib.dump(xgb_model, f'trained_models/xgboost_model_{suffix}.pkl')\n",
                "\n",
                "    # --- LightGBM ---\n",
                "    print(\"  ‚è≥ LightGBM...\")\n",
                "    lgb_model = lgb.LGBMRegressor(\n",
                "        n_estimators=1000,\n",
                "        learning_rate=0.05,\n",
                "        num_leaves=31,\n",
                "        subsample=0.8,\n",
                "        colsample_bytree=0.8,\n",
                "        random_state=42,\n",
                "        n_jobs=-1\n",
                "    )\n",
                "    lgb_model.fit(\n",
                "        X_train, y_train,\n",
                "        eval_set=[(X_test, y_test)],\n",
                "        eval_metric='rmse',\n",
                "        callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(0)]\n",
                "    )\n",
                "    \n",
                "    # √âvaluation LGBM\n",
                "    lgb_pred = lgb_model.predict(X_test)\n",
                "    lgb_rmse = np.sqrt(mean_squared_error(y_test, lgb_pred))\n",
                "    print(f\"    ‚úÖ LGB RMSE: {lgb_rmse:.4f}\")\n",
                "    \n",
                "    # Sauvegarde LGBM\n",
                "    joblib.dump(lgb_model, f'trained_models/lightgbm_model_{suffix}.pkl')\n",
                "    \n",
                "    return y_test, xgb_pred, lgb_pred"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9743d904",
            "metadata": {},
            "source": [
                "## Ex√©cution pour target_7 et target_30"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9bc858ea",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Target 7\n",
                "y7, xgb7, lgb7 = train_evaluate_save('target_7', '7')\n",
                "\n",
                "# Target 30\n",
                "y30, xgb30, lgb30 = train_evaluate_save('target_30', '30')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "900162f8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualisation 7 jours\n",
                "plt.figure(figsize=(15, 5))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(y7.values[:100], label='R√©el', alpha=0.6)\n",
                "plt.plot(xgb7[:100], label='XGB', alpha=0.6)\n",
                "plt.plot(lgb7[:100], label='LGB', alpha=0.6)\n",
                "plt.title(\"Target 7 Jours (Zoom 100)\")\n",
                "plt.legend()\n",
                "\n",
                "# Visualisation 30 jours\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(y30.values[:100], label='R√©el', alpha=0.6)\n",
                "plt.plot(xgb30[:100], label='XGB', alpha=0.6)\n",
                "plt.plot(lgb30[:100], label='LGB', alpha=0.6)\n",
                "plt.title(\"Target 30 Jours (Zoom 100)\")\n",
                "plt.legend()\n",
                "\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
