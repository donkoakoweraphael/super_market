{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model Training: Boosting Models (XGBoost & LightGBM)\n",
                "\n",
                "Ce notebook charge les donn√©es pr√©trait√©es et entra√Æne des mod√®les de gradient boosting pour la pr√©vision de la demande."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import xgboost as xgb\n",
                "import lightgbm as lgb\n",
                "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
                "import joblib\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Cr√©ation du dossier pour les mod√®les si n√©cessaire\n",
                "os.makedirs('trained_models', exist_ok=True)\n",
                "\n",
                "print(\"‚úÖ Biblioth√®ques import√©es et dossier v√©rifi√©.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Chargement des Donn√©es\n",
                "Nous utilisons les datasets g√©n√©r√©s par le notebook de pr√©traitement."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_path = 'train_boosting.csv'\n",
                "test_path = 'test_boosting.csv'\n",
                "\n",
                "if not os.path.exists(train_path) or not os.path.exists(test_path):\n",
                "    raise FileNotFoundError(\"Les fichiers train_boosting.csv ou test_boosting.csv sont introuvables. Veuillez ex√©cuter le notebook pretraitement.ipynb d'abord.\")\n",
                "\n",
                "train_df = pd.read_csv(train_path)\n",
                "test_df = pd.read_csv(test_path)\n",
                "\n",
                "print(f\"üì¶ Train shape: {train_df.shape}\")\n",
                "print(f\"üì¶ Test shape: {test_df.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0d3eec37",
            "metadata": {},
            "source": [
                "## Pr√©paration des Features et Target\n",
                "Nous allons utiliser `target_7` pour pr√©dire la demande √† 7 jours. Nous excluons `target_30` des features. Nous filtrons aussi les colonnes non-num√©riques."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5d60ec0d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# D√©finition des cibles et features √† exclure\n",
                "target_col = 'target_7'\n",
                "drop_cols = ['target_7', 'target_30']\n",
                "\n",
                "# S√©paration X et y\n",
                "X_train = train_df.drop(columns=drop_cols, errors='ignore')\n",
                "y_train = train_df[target_col]\n",
                "\n",
                "X_test = test_df.drop(columns=drop_cols, errors='ignore')\n",
                "y_test = test_df[target_col]\n",
                "\n",
                "# Suppression des colonnes non num√©riques (Date, ID, etc.)\n",
                "X_train = X_train.select_dtypes(include=[np.number])\n",
                "X_test = X_test.select_dtypes(include=[np.number])\n",
                "\n",
                "# Alignement des colonnes (au cas o√π)\n",
                "X_train = X_train[X_test.columns]\n",
                "\n",
                "print(f\"Features utilis√©es: {len(X_train.columns)}\")\n",
                "print(f\"Colonnes conserv√©es: {list(X_train.columns)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Entra√Ænement XGBoost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"‚è≥ Entra√Ænement XGBoost en cours...\")\n",
                "xgb_model = xgb.XGBRegressor(\n",
                "    n_estimators=1000,\n",
                "    learning_rate=0.05,\n",
                "    max_depth=6,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    early_stopping_rounds=50,\n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "xgb_model.fit(\n",
                "    X_train, y_train,\n",
                "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
                "    verbose=100\n",
                ")\n",
                "\n",
                "print(\"‚úÖ XGBoost entra√Æn√©.\")\n",
                "\n",
                "# Sauvegarde\n",
                "xgb_path = 'trained_models/xgboost_model.pkl'\n",
                "joblib.dump(xgb_model, xgb_path)\n",
                "print(f\"üíæ Mod√®le sauvegard√© sous : {xgb_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Entra√Ænement LightGBM"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"‚è≥ Entra√Ænement LightGBM en cours...\")\n",
                "lgb_model = lgb.LGBMRegressor(\n",
                "    n_estimators=1000,\n",
                "    learning_rate=0.05,\n",
                "    num_leaves=31,\n",
                "    subsample=0.8,\n",
                "    colsample_bytree=0.8,\n",
                "    random_state=42,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "lgb_model.fit(\n",
                "    X_train, y_train,\n",
                "    eval_set=[(X_test, y_test)],\n",
                "    eval_metric='rmse',\n",
                "    callbacks=[lgb.early_stopping(stopping_rounds=50), lgb.log_evaluation(100)]\n",
                ")\n",
                "\n",
                "print(\"‚úÖ LightGBM entra√Æn√©.\")\n",
                "\n",
                "# Sauvegarde\n",
                "lgb_path = 'trained_models/lightgbm_model.pkl'\n",
                "joblib.dump(lgb_model, lgb_path)\n",
                "print(f\"üíæ Mod√®le sauvegard√© sous : {lgb_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## √âvaluation des Mod√®les"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_model(model, name, X, y):\n",
                "    preds = model.predict(X)\n",
                "    rmse = np.sqrt(mean_squared_error(y, preds))\n",
                "    mae = mean_absolute_error(y, preds)\n",
                "    print(f\"--- {name} ---\")\n",
                "    print(f\"RMSE: {rmse:.4f}\")\n",
                "    print(f\"MAE:  {mae:.4f}\")\n",
                "    return preds\n",
                "\n",
                "print(\"\\nüìä √âvaluation sur le Test Set :\")\n",
                "xgb_preds = evaluate_model(xgb_model, \"XGBoost\", X_test, y_test)\n",
                "lgb_preds = evaluate_model(lgb_model, \"LightGBM\", X_test, y_test)\n",
                "\n",
                "# Visualisation rapide\n",
                "plt.figure(figsize=(15, 6))\n",
                "plt.plot(y_test.values[:100], label='R√©el', alpha=0.7)\n",
                "plt.plot(xgb_preds[:100], label='XGBoost Pred', alpha=0.7)\n",
                "plt.plot(lgb_preds[:100], label='LightGBM Pred', alpha=0.7)\n",
                "plt.title(\"Comparaison Pr√©dictions vs R√©el (100 premiers points)\")\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
